model:
  d_fft: 1024
  d_model: 512
  dropout: 0.1
  heads: 4
  layers: 6
  type: transformer
paths:
  checkpoint_dir: checkpoints
  data_dir: datasets
preprocessing:
  char_repeats: 3
  languages:
  - hsb
  - dsb
  lowercase: true
  n_val: 5000
  phoneme_symbols:
  - "\xED"
  - "\u017E"
  - "\xFA"
  - c
  - t
  - d
  - p
  - "\xE9"
  - x
  - h
  - w
  - a
  - z
  - "\u0159"
  - q
  - f
  - v
  - "\u0144"
  - "\u0148"
  - "\u0119"
  - "\xE4"
  - i
  - m
  - s
  - "\xDF"
  - j
  - "\u0155"
  - g
  - "\u0107"
  - y
  - "\xE1"
  - r
  - "\xAD"
  - "\u0142"
  - "\u017A"
  - "\u015B"
  - "\u0161"
  - u
  - k
  - o
  - "\xF3"
  - "\xE0"
  - "\xFD"
  - b
  - "\u017C"
  - n
  - "\u011B"
  - "\xF6"
  - l
  - "\xFC"
  - e
  - "\u010D"
  text_symbols: "\xED\u017E\xFActdp\xE9xhwaz\u0159qfv\u0144\u0148\u0119\xE4ims\xDF\
    j\u0155g\u0107y\xE1r\xAD\u0142\u017A\u015B\u0161uko\xF3\xE0\xFDb\u017Cn\u011B\xF6\
    l\xFCe\u010D"
training:
  batch_size: 32
  batch_size_val: 32
  checkpoint_steps: 100000
  epochs: 10
  generate_steps: 500
  learning_rate: 0.0001
  n_generate_samples: 10
  scheduler_plateau_factor: 0.5
  scheduler_plateau_patience: 10
  store_phoneme_dict_in_model: true
  validate_steps: 500
  warmup_steps: 100
